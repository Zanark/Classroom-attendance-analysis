{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math \n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omm/WorkStuff/Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join('', \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "print(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omm/WorkStuff/Mask_RCNN/images\n"
     ]
    }
   ],
   "source": [
    "print(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir='mask_rcnn_coco.hy', config=config)\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/home/omm/Downloads/group2.jpeg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f829cdda828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skimage.io.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (720, 1280, 3)        min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1280.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = model.detect([image], verbose=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.021062135696411\n"
     ]
    }
   ],
   "source": [
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = r['masks'].shape\n",
    "height = y[0]\n",
    "width = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f829d1b5160>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wImage = np.zeros([height, width, 3], dtype=np.uint8)\n",
    "wImage.fill(255)\n",
    "plt.imshow(wImage)\n",
    "\n",
    "bImage = np.zeros([height, width, 3], dtype=np.uint8)\n",
    "plt.imshow(bImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image,masks):\n",
    "    \n",
    "    n=masks.shape[2]\n",
    "    image.fill(0)\n",
    "    \n",
    "    for i in range(n):\n",
    "        mask = masks[:,:,i]\n",
    "        image[:,:,0] = np.where(mask==1,\n",
    "                            (image[:,:,0] * 0) + 255,\n",
    "                            image[:,:,0])\n",
    "        image[:,:,1] = np.where(mask==1,\n",
    "                            (image[:,:,1] * 0) + 255,\n",
    "                            image[:,:,1])\n",
    "        image[:,:,2] = np.where(mask==1,\n",
    "                            (image[:,:,2] * 0) + 255,\n",
    "                            image[:,:,2])\n",
    "    \n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_mask(image, r['masks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f829d2e8f28>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-20e9708bacc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     frame = apply_mask(frame,\n",
      "\u001b[0;32m~/WorkStuff/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;31m# Run object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2523\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmolded_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m         \u001b[0;31m# Process detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_video = 'Raw Video- The President Takes a Surprise Walk.mp4' \n",
    "capture = cv2.VideoCapture(input_video)\n",
    "\n",
    "fps = 25.0\n",
    "width = int(capture.get(3))\n",
    "height = int(capture.get(4))\n",
    "fcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')\n",
    "out = cv2.VideoWriter(\"new_video.avi\", fcc, fps, (width, height))\n",
    "\n",
    "while True: \n",
    "    ret, frame = capture.read()\n",
    "    results = model.detect([frame], verbose=0)\n",
    "    r = results[0]\n",
    "    frame = apply_mask(frame,\n",
    "                r['masks'])\n",
    "                        \n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
